{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf2de5001043c09c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T09:52:28.480943Z",
     "start_time": "2024-06-30T09:52:28.475688Z"
    }
   },
   "outputs": [],
   "source": [
    "#подключаем нужные библиотеки:\n",
    "import requests #подключила биб-ку для работы с post/get запросами к сайту \n",
    "import pandas as pd #подключили биб-ку для работы с фреймом данных\n",
    "import numpy as np #подключили биб-ку для работы с массивом\n",
    "from bs4 import BeautifulSoup #подключили биб-ку супа\n",
    "from datetime import datetime #подключили биб-ку для получения системной даты и времени (запишется в название выходного файла)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf568cbd1512ce88",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T09:52:48.479717Z",
     "start_time": "2024-06-30T09:52:43.543374Z"
    }
   },
   "outputs": [],
   "source": [
    "user_url = \"https://otus.ru/\"\n",
    "try:\n",
    "    user_url = input(\"Введите адрес сайта: \") #запрашиваем у польз-ля адрес сайта\n",
    "except:\n",
    "    user_url = \"https://otus.ru/\" #по умолчанию обращаемся к сайту Отуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ea1d6fc2d66f5cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T10:10:48.167258Z",
     "start_time": "2024-06-30T10:10:37.580568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список найденных URL для сайта https://otus.ru/: \n",
      "<built-in function array>\n",
      "https://direct.otus.ru\n",
      "https://landing.otus.ru/about-otus \n",
      "https://landing.otus.ru/gallery\n",
      "https://vk.com/club145052891\n",
      "https://zen.yandex.ru/id/5bbcbc1ba5bd5400a990e7d9\n",
      "https://www.youtube.com/channel/UCetgtvy93o3i3CvyGXKFU3g\n",
      "https://t.me/Otusjava\n",
      "https://t.me/joinchat/JMakp0NXc-L8nNneHCtx7A\n",
      "http://sk.ru/?utm_source=otus\n",
      "https://ktsstudio.com/?utm_source=otus\n",
      "http://goodlookin.ru/?utm_source=otus\n",
      "Произведем парсинг каждого найденного сайта в первичной выборке на наличие ссылок.\n",
      "Выгрузка данных завершена!\n"
     ]
    }
   ],
   "source": [
    "def get_hyp_array(a_user_url):\n",
    "    response = requests.get(a_user_url) #обратились к сайту\n",
    "    #print(response) #поверили - работает ли сайт - если 200 - то ответ стабильный, 404 - нет доступа\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\") #взяли страничку с сайта и подключили к ней метод парсера- получили объект суп\n",
    "    ar = np.array #завели массив\n",
    "    for a in soup.find_all('a', href=True): #нашли все теги (итератор цикла a, тег поиска - a) с ссылками href\n",
    "        if a['href'].startswith(\"http\"): #выбрали из этих ссылок только ссылки на др сайты (были еще ссылки на странички этого же, \"парсируемого\" сайта)\n",
    "            ar = np.append(ar, a['href']) #добавили в массив\n",
    "    return ar\n",
    "\n",
    "try:\n",
    "    head_array = get_hyp_array(user_url)\n",
    "except:\n",
    "    user_url = \"https://otus.ru/\"\n",
    "    print(\"Ссылки <a href> по введенному адресу не найдены. Поиск произведется на сайте {f}\".format(f = user_url))\n",
    "    head_array = get_hyp_array(user_url)\n",
    "\n",
    "if len(head_array) > 0:\n",
    "    print(\"Список найденных URL для сайта {f}: \".format(f = user_url))\n",
    "    for i in range(len(head_array)):\n",
    "        print(head_array[i]) #выводим первичный список ссылок, п.3 дз1\n",
    "\n",
    "    #выводим список ссылок для каждой из первичного списка:\n",
    "\n",
    "    print(\"Произведем парсинг каждого найденного сайта в первичной выборке на наличие ссылок.\")\n",
    "\n",
    "    #запрашиваем, куда выводить рез-ты:\n",
    "    i = 0\n",
    "    choice = 2\n",
    "    while i <= 2:\n",
    "        try:\n",
    "            choice = int(input(\"Выводить результаты на экран (1) или в файл (2): \"))\n",
    "            if choice in (1,2):\n",
    "                break\n",
    "            else:\n",
    "                if i < 2:\n",
    "                    print(\"Для ввода доступны клавиши 1 или 2, повторите попытку.\")\n",
    "                else:\n",
    "                    print(\"Выбор не сделан, по умолчанию результат выведется в файл\")\n",
    "                    choice = 2\n",
    "                    break\n",
    "            i += 1\n",
    "        except:\n",
    "            if i < 2:\n",
    "                print(\"Для ввода доступны клавиши 1 или 2, повторите попытку.\")\n",
    "            else:\n",
    "                print(\"Выбор не сделан, по умолчанию результат выведется в файл\")\n",
    "                choice = 2\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    #выводим рез-ты:\n",
    "    if choice == 2: #в случае, если выбрали сохранение результатов в файл\n",
    "        current_datetime = str(datetime.now()).replace(\":\",\"-\").replace(\".\",\"-\")\n",
    "        filename = \"hyperlinks_dz1\" + \"_\" + current_datetime + \".csv\" #имя выходного файла\n",
    "    \n",
    "    for i in range(len(head_array)):\n",
    "        try:\n",
    "            second_array = [] #обнуляем массив\n",
    "            second_array = get_hyp_array(head_array[i])\n",
    "            if choice == 1: #выводим список сайтов в консоль\n",
    "                print(\"Список найденных URL для сайта {f}: \".format(f = head_array[i]))\n",
    "                try:\n",
    "                    if len(second_array) > 0:\n",
    "                        for j in range(len(second_array)):\n",
    "                            print(second_array[j])\n",
    "                except:\n",
    "                    print(\"   На сайте {f} отсутствуют ссылки на другие сайты! \".format(f = head_array[i]))\n",
    "            elif choice == 2: #вывели список сайтов в файл\n",
    "                try:\n",
    "                    if len(second_array) > 0:\n",
    "                        df1 = pd.DataFrame({\"hyperlinks\": \"Список найденных URL для сайта {f}: \".format(f = head_array[i])}, index = [0])\n",
    "                        df2 = pd.DataFrame({\"hyperlinks\": second_array}) #переписали из массива в датафрейм\n",
    "                        df = pd.concat([df1, df2]) #соединили: в конец датафрейм1 добавили основной блок с ссылками для текущего сайта - датафрейм 2\n",
    "                        df.to_csv(filename, mode = 'a', index = False) #загнали рез-ты в файл, через добавление в конец файла\n",
    "                except:\n",
    "                    df1 = pd.DataFrame({\"hyperlinks\": \"Список найденных URL для сайта {f}: \".format(f = head_array[i])}, index = [0])     \n",
    "                    df2 = pd.DataFrame({\"hyperlinks\": \"   На сайте {f} отсутствуют ссылки на другие сайты! \".format(f = head_array[i])}, index = [0])\n",
    "                    df = pd.concat([df1, df2]) #соединили: в конец датафрейм1 добавили основной блок с ссылками для текущего сайта - датафрейм 2\n",
    "                    df.to_csv(filename, mode = 'a', index = False) #загнали рез-ты в файл, через добавление в конец файла\n",
    "        except:\n",
    "            continue\n",
    "    print(\"Выгрузка данных завершена!\")\n",
    "else:\n",
    "    print(\"На сайте {f} отсутствуют ссылки на другие сайты!\".format(f = user_url))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
